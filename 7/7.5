import http.client
import os
from urllib.parse import urljoin
from bs4 import BeautifulSoup
import requests

def fetch_images_from_page(url, visited):
    # Проверяем, если URL уже был посещен
    if url in visited:
        return
    visited.add(url)

    # Убедимся, что URL начинается с http://
    if not url.startswith("http://"):
        url = "http://" + url

    # Извлекаем хост и путь из URL
    host = url.split("/")[2]
    path = "/" + "/".join(url.split("/")[3:]) or "/"

    # Создаем соединение
    connection = http.client.HTTPConnection(host)

    try:
        # Отправляем GET-запрос
        connection.request("GET", path)

        # Получаем ответ
        response = connection.getresponse()

        # Проверяем статус ответа
        print(f"Статус: {response.status} {response.reason}")

        # Читаем содержимое страницы
        page_content = response.read().decode('utf-8')

        # Парсим HTML с помощью BeautifulSoup
        soup = BeautifulSoup(page_content, 'html.parser')

        # Извлекаем все изображения
        img_tags = soup.find_all('img')
        img_urls = [urljoin(url, img['src']) for img in img_tags if 'src' in img.attrs]

        # Создаем директорию для изображений, если она не существует
        os.makedirs('images', exist_ok=True)

        # Загружаем и сохраняем каждое изображение
        for img_url in img_urls:
            try:
                img_data = requests.get(img_url).content
                img_name = os.path.join('images', img_url.split('/')[-1])
                with open(img_name, 'wb') as f:
                    f.write(img_data)
                print(f"Сохранено изображение: {img_name}")
            except Exception as e:
                print(f"Не удалось загрузить изображение {img_url}: {e}")

        # Извлекаем все ссылки на странице
        links = soup.find_all('a')
        for link in links:
            href = link.get('href')
            if href and href.startswith(('http://', 'https://')):
                fetch_images_from_page(href, visited)

    except Exception as e:
        print(f"Произошла ошибка: {e}")

    finally:
        connection.close()

if __name__ == "__main__":
    visited_links = set()
    fetch_images_from_page("http://rokot.ibst.psu/anatoly/", visited_links)
